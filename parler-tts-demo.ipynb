{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":210503687,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":206.684149,"end_time":"2024-11-25T15:30:15.168841","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-25T15:26:48.484692","version":"2.6.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"EjHd4T0r0HHA","cell_type":"markdown","source":"### Preparation","metadata":{"id":"EjHd4T0r0HHA"}},{"id":"5ec82dce","cell_type":"code","source":"!pip install git+https://github.com/huggingface/parler-tts.git -q","metadata":{"papermill":{"duration":51.634186,"end_time":"2024-11-25T15:27:42.509125","exception":false,"start_time":"2024-11-25T15:26:50.874939","status":"completed"},"scrolled":true,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"5ec82dce","outputId":"749f940c-5daf-4e51-919b-7f1a8f0636cf","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:35:05.588574Z","iopub.execute_input":"2024-12-19T01:35:05.589026Z","iopub.status.idle":"2024-12-19T01:35:55.565475Z","shell.execute_reply.started":"2024-12-19T01:35:05.588974Z","shell.execute_reply":"2024-12-19T01:35:55.564525Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"id":"OUKzjEaL0J7L","cell_type":"markdown","source":"### Demo","metadata":{"id":"OUKzjEaL0J7L"}},{"id":"RLcl0c7I0Pzg","cell_type":"code","source":"!pip install gradio -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLcl0c7I0Pzg","outputId":"5a61a82d-1baa-45fb-b9fe-2a4ae568eefa","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:35:56.150848Z","iopub.execute_input":"2024-12-19T01:35:56.151188Z","iopub.status.idle":"2024-12-19T01:36:10.940570Z","shell.execute_reply.started":"2024-12-19T01:35:56.151152Z","shell.execute_reply":"2024-12-19T01:36:10.939266Z"}},"outputs":[],"execution_count":6},{"id":"jLUg_icK0NU8","cell_type":"code","source":"import torch\nimport gradio as gr\nfrom parler_tts import ParlerTTSForConditionalGeneration\nfrom transformers import AutoTokenizer\nimport numpy as np\nimport soundfile as sf\nimport os","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLUg_icK0NU8","outputId":"0ba2acd7-24be-4e4a-99bb-4ceaaf21b2c6","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:36:10.942372Z","iopub.execute_input":"2024-12-19T01:36:10.942842Z","iopub.status.idle":"2024-12-19T01:36:34.062780Z","shell.execute_reply.started":"2024-12-19T01:36:10.942795Z","shell.execute_reply":"2024-12-19T01:36:34.061956Z"}},"outputs":[],"execution_count":7},{"id":"afwfJO7V0Dz9","cell_type":"code","source":"# Set up the model and tokenizer\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ParlerTTSForConditionalGeneration.from_pretrained(\n    \"Amadeus99/parler-tts-mini-v1-yt-v1\",\n    torch_dtype=torch.float16\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(\"Amadeus99/parler-tts-mini-v1-yt-v1\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afwfJO7V0Dz9","outputId":"4897aadf-1dc2-4fb8-f3db-fc9940603892","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:36:34.063884Z","iopub.execute_input":"2024-12-19T01:36:34.064438Z","iopub.status.idle":"2024-12-19T01:38:11.438475Z","shell.execute_reply.started":"2024-12-19T01:36:34.064411Z","shell.execute_reply":"2024-12-19T01:38:11.437552Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/7.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8893e68358fd4d078272a0279a1112a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.76G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446b22c90b7b44a7b1f54e5ab7e15ecf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2308357a885840a3ae7b4346cff39d29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e742b7ec9a6a4062bc374a943d3c6c90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dd5eca20e8d448d834734ca57129167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c774a6aa44e45028442cfc244f43ecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455dc132aa1a49c990d3510930afd396"}},"metadata":{}}],"execution_count":8},{"id":"YowVHbLG0qNx","cell_type":"code","source":"def generate_audio(prompt, description):\n    \"\"\"\n    Generate audio from text prompt and voice description\n\n    Args:\n        prompt (str): The text to be converted to speech\n        description (str): Description of the voice characteristics\n\n    Returns:\n        str: Path to the generated audio file\n    \"\"\"\n    try:\n        # Ensure inputs are on the correct device\n        input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n        prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n\n        # Generate audio\n        generation = model.generate(\n            input_ids=input_ids,\n            prompt_input_ids=prompt_input_ids\n        )\n\n        # Convert to numpy array\n        audio_arr = generation.cpu().numpy().squeeze()\n\n        # Ensure output directory exists\n        os.makedirs(\"outputs\", exist_ok=True)\n\n        # Save the audio file\n        output_path = \"outputs/generated_audio.wav\"\n        sf.write(output_path, audio_arr.astype(np.float32), model.config.sampling_rate)\n\n        return output_path\n\n    except Exception as e:\n        return f\"Error generating audio: {str(e)}\"","metadata":{"id":"YowVHbLG0qNx","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:38:11.439723Z","iopub.execute_input":"2024-12-19T01:38:11.439997Z","iopub.status.idle":"2024-12-19T01:38:11.445912Z","shell.execute_reply.started":"2024-12-19T01:38:11.439972Z","shell.execute_reply":"2024-12-19T01:38:11.445043Z"}},"outputs":[],"execution_count":9},{"id":"ejx2LY4l0wa9","cell_type":"code","source":"# Create Gradio interface\ndemo = gr.Interface(\n    fn=generate_audio,\n    inputs=[\n        gr.Textbox(label=\"Text Prompt\",\n                   placeholder=\"Enter the text you want to convert to speech\"),\n        gr.Textbox(label=\"Voice Description\",\n                   placeholder=\"Describe the voice characteristics (e.g., 'A man speaks in a very monotone voice')\",\n                   value=\"A man speaks in a very monotone voice\")\n    ],\n    outputs=[\n        gr.Audio(label=\"Generated Speech\", type=\"filepath\")\n    ],\n    title=\"Parler TTS Audio Generation\",\n    description=\"Generate speech using Parler TTS model. Provide a text prompt and voice description.\",\n    examples=[\n        [\n            \"halo, ini adalah model untuk konversi kalimat ke suara\",\n            \"A man speaks in a very monotone voice\"\n        ]\n    ]\n)","metadata":{"id":"ejx2LY4l0wa9","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:38:11.448697Z","iopub.execute_input":"2024-12-19T01:38:11.448951Z","iopub.status.idle":"2024-12-19T01:38:11.961030Z","shell.execute_reply.started":"2024-12-19T01:38:11.448928Z","shell.execute_reply":"2024-12-19T01:38:11.960348Z"}},"outputs":[],"execution_count":10},{"id":"a4lK6l_O1DxL","cell_type":"code","source":"demo.launch()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"a4lK6l_O1DxL","outputId":"c68e6275-728d-4979-8068-411510671e67","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:38:11.963281Z","iopub.execute_input":"2024-12-19T01:38:11.963561Z","iopub.status.idle":"2024-12-19T01:38:13.205090Z","shell.execute_reply.started":"2024-12-19T01:38:11.963528Z","shell.execute_reply":"2024-12-19T01:38:13.204346Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://6a67031d1788f46198.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://6a67031d1788f46198.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"}],"execution_count":11}]}